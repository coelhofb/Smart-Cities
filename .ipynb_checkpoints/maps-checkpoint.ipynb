{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import gmaps\n",
    "import folium\n",
    "import gmaps.geojson_geometries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "import geopandas\n",
    "# import shapely\n",
    "\n",
    "from config import gkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in all cvs files\n",
    "cookco ='cookco_zips.csv'\n",
    "census = 'census_data_chi_zips.csv'\n",
    "walkscore = 'chi_zip_scores.csv'\n",
    "\n",
    "l_stops = 'cta_l_stops.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'census_data_chi_zips.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a3812dc3243f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# read all csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcookco_table\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcookco\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcensus_table\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcensus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mws_table\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwalkscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0ml_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml_stops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\KatySpace\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\KatySpace\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\KatySpace\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\KatySpace\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\KatySpace\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'census_data_chi_zips.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# read all csv\n",
    "cookco_table= pd.read_csv(cookco)\n",
    "census_table= pd.read_csv(census)\n",
    "ws_table= pd.read_csv(walkscore)\n",
    "l_table = pd.read_csv(l_stops)\n",
    "\n",
    "l_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge cook and walkscore\n",
    "merge_table1 = pd.merge(cookco_table, ws_table, left_on=\"ZipCode\", \n",
    "                       right_on='zipcode', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge initial merge with census\n",
    "merge_table2 = pd.merge(merge_table1, census_table, left_on=\"ZipCode\", \n",
    "                       right_on=\"Zipcode\",how=\"left\")\n",
    "\n",
    "#merge_table2.head()\n",
    "merge_table = merge_table2.drop(['Unnamed: 0_x', 'Unnamed: 0_y', 'Unnamed: 0'], axis=1)\n",
    "\n",
    "chicago_table = merge_table.drop(index=53)\n",
    "chicago_table.fillna(0)\n",
    "\n",
    "#merge_table\n",
    "\n",
    "chicago_table['LAT'].astype(dtype=float)\n",
    "chicago_table['LNG'].astype(dtype=float)\n",
    "chicago_table['HousingUnits'].astype(dtype=int)\n",
    "\n",
    "chicago_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colors\n",
    "\n",
    "colors = 'F86006', 'F46669', 'E4AE32', '33CAC8', '175556', '04ACA4','8BBFE5','EEA54A','D0CA29'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# folium maps (walk, transit and bike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in illinois geojson\n",
    "zip_boundaries = requests.get('https://raw.githubusercontent.com/OpenDataDE/State-zip-code-GeoJSON/master/il_illinois_zip_codes_geo.min.json')\n",
    "#zip_json = zip_boundaries.\n",
    "all_zips_dict = zip_boundaries.json()\n",
    "\n",
    "# create empty list, with beginning of geojson to append just chicago zips\n",
    "chicago_zips = {\"type\": \"FeatureCollection\", \"features\": []}\n",
    "\n",
    "#put the zipcodes into a list to compare to the json zips\n",
    "chi_city_zip = pd.to_numeric(merge_table['ZipCode']).tolist()\n",
    "\n",
    "\n",
    "# print(chi_city_zip)\n",
    "# max_count = 100\n",
    "# actual_count = 0\n",
    "\n",
    "# loop through geojson to parse out only the chicago zip codes\n",
    "for feature in all_zips_dict[\"features\"]:\n",
    "    #print(feature[\"properties\"].keys())\n",
    "    zip = int(feature[\"properties\"][\"ZCTA5CE10\"])\n",
    "    feature[\"zipcode\"] = zip\n",
    "    if zip in chi_city_zip:\n",
    "        feature[\"fillColor\"] = 'green'\n",
    "        chicago_zips[\"features\"].append(feature)\n",
    "#        print(\"Chicago!!!!\")\n",
    "#         actual_count += 1\n",
    "#     if max_count <= actual_count:\n",
    "#        break\n",
    "\n",
    "#print(chicago_zips)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create linear color scale\n",
    "from branca.colormap import linear\n",
    "\n",
    "colormap_walk = linear.YlGn_09.scale(\n",
    "    chicago_table.walkscore.min(),\n",
    "    chicago_table.walkscore.max())\n",
    "print(colormap_walk(5.0))\n",
    "\n",
    "colormap_walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# WALK MAP using lambda function\n",
    "# create folio choropleth base map\n",
    "walk_map = folium.Map(location = [41.885310,-87.622116], zoom_start=11, tiles='Stamen Terrain')\n",
    "# folium.GeoJson(chicago_zips).add_to(transit)\n",
    "\n",
    "#change type of merge table zipcodes\n",
    "chicago_table['zipcode'].astype(dtype=int)\n",
    "chicago_table['walkscore'].astype(dtype=int)\n",
    "\n",
    "# to compare to the geojson the table has to be a dictionary\n",
    "chicago_dict_walk= chicago_table.set_index('zipcode')['walkscore']\n",
    "\n",
    "#using the lambda funtion to color the zip boundary lines and add to the walk map\n",
    "folium.GeoJson(\n",
    "    chicago_zips,\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': '#f86006',\n",
    "        'color': 'black',\n",
    "        'weight': 2,\n",
    "    }\n",
    ").add_to(walk_map)\n",
    "walk_map\n",
    "\n",
    "folium.GeoJson(\n",
    "    chicago_zips,\n",
    "    name='walkscore',\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': colormap_walk(chicago_dict_walk[feature['zipcode']]),\n",
    "        'color': 'black',\n",
    "        'weight': 1,\n",
    "        'dashArray': '5, 5',\n",
    "        'fillOpacity': 0.9,\n",
    "    }\n",
    ").add_to(walk_map)\n",
    "\n",
    "colormap_walk.caption = 'Walkscore'\n",
    "colormap_walk.add_to(walk_map)\n",
    "\n",
    "walk_map\n",
    "\n",
    "walk_map.save('walkscore.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# WALK MAP using lambda function\n",
    "# create folio choropleth base map\n",
    "walk_map = folium.Map(location = [41.885310,-87.622116], zoom_start=11, tiles='Stamen Terrain')\n",
    "# folium.GeoJson(chicago_zips).add_to(transit)\n",
    "\n",
    "\n",
    "# to compare to the geojson the table has to be a dictionary\n",
    "#chicago_dict_walk= chicago_table.set_index('zipcode')['walkscore']\n",
    "\n",
    "walk_map.choropleth(geo_data=chicago_zips,\n",
    "                       data=chicago_table,\n",
    "                       columns=['zipcode', 'walkscore'],\n",
    "                       key_on='zipcode',\n",
    "                       fill_color='YlOrBr',\n",
    "                       fill_opacity = .7,\n",
    "                       legend_name = \"Walk Score\",\n",
    "                      )\n",
    "\n",
    "\n",
    "walk_map\n",
    "\n",
    "walk_map.save('walkscore.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSIT MAP - using m.choropleth\n",
    "# create folio choropleth base map\n",
    "transit_map = folium.Map(location = [41.885310,-87.622116], zoom_start=11, tiles='Stamen Terrain')\n",
    "\n",
    "#change type of merge table zipcodes\n",
    "\n",
    "# to compare to the geojson the table has to be a dictionary\n",
    "#chicago_dict_transit= chicago_table.set_index('zipcode')['transitscore']\n",
    "\n",
    "transit_map.choropleth(geo_data=chicago_zips,\n",
    "                       data=chicago_table,\n",
    "                       columns=['zipcode', 'transitscore'],\n",
    "                       key_on='zipcode',\n",
    "                       fill_color='GnBu',\n",
    "                       fill_opacity = .9,\n",
    "                       legend_name = \"Transitscore\",\n",
    "                      )\n",
    "\n",
    "transit_map\n",
    "transit_map.save('transitscore.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIKE MAP\n",
    "# create folio choropleth base map\n",
    "bike_map = folium.Map(location = [41.885310,-87.622116], zoom_start=11, tiles='Stamen Terrain')\n",
    "\n",
    "#change type of merge table zipcodes\n",
    "\n",
    "# to compare to the geojson the table has to be a dictionary\n",
    "#chicago_dict_bike= chicago_table.set_index('zipcode')['bikescore']\n",
    "\n",
    "bike_map.choropleth(geo_data=chicago_zips,\n",
    "                       data=chicago_table,\n",
    "                       columns=['zipcode', 'bikescore'],\n",
    "                       key_on='zipcode',\n",
    "                       fill_color='OrRd',\n",
    "                       fill_opacity = .9,\n",
    "                       legend_name = \"Bikescore\",\n",
    "                      )\n",
    "\n",
    "bike_map\n",
    "\n",
    "bike_map.save('bikescore.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# demographics maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEDIAN AGE\n",
    "# create folio choropleth base map\n",
    "age_map = folium.Map(location = [41.885310,-87.622116], zoom_start=11, tiles='Stamen Terrain')\n",
    "\n",
    "#change data type\n",
    "chicago_table['MedianAge'].astype(dtype=float)\n",
    "\n",
    "# to compare to the geojson the table has to be a dictionary\n",
    "#chicago_dict_age= chicago_table.set_index('zipcode')['MedianAge']\n",
    "\n",
    "age_map.choropleth(geo_data=chicago_zips,\n",
    "                       data=chicago_table,\n",
    "                       columns=['zipcode', 'MedianAge'],\n",
    "                       key_on='zipcode',\n",
    "                       fill_color='GnBu',\n",
    "                       fill_opacity = .9,\n",
    "                       legend_name = \"Median Age\",\n",
    "                      )\n",
    "\n",
    "age_map\n",
    "age_map.save('age_map.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEDIAN HOUSEHOLD INCOME\n",
    "# create folio choropleth base map\n",
    "income_map = folium.Map(location = [41.885310,-87.622116], zoom_start=11, tiles='Stamen Terrain')\n",
    "\n",
    "#change data type\n",
    "chicago_table['MedianHouseholdIncome'].astype(dtype=float)\n",
    "\n",
    "# to compare to the geojson the table has to be a dictionary\n",
    "#chicago_dict_age= chicago_table.set_index('zipcode')['MedianAge']\n",
    "\n",
    "income_map.choropleth(geo_data=chicago_zips,\n",
    "                       data=chicago_table,\n",
    "                       columns=['zipcode', 'MedianHouseholdIncome'],\n",
    "                       key_on='zipcode',\n",
    "                       fill_color='RdPu',\n",
    "                       fill_opacity = .9,\n",
    "                       legend_name = \"Median Household Income\",\n",
    "                      )\n",
    "\n",
    "income_map\n",
    "income_map.save('income_map.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#city inforamtion\n",
    "\n",
    "gmaps.configure(api_key='AIzaSyDTsBGb30a6KHnFUU8ECzEa1xRM0O9tefw')\n",
    "\n",
    "#locations = \"Chicago, Illinois\"\n",
    "\n",
    "# target_url = \"https://maps.googleapis.com/maps/api/geocode/json?\" \\\n",
    "#     \"address=%s&key=%s\" % (target_city, gkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_geojson = gmaps.geojson_geometries.load_geometry('countries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "locations = merge_table[['LAT','LNG']]\n",
    "\n",
    "weights = merge_table['walkscore']\n",
    "\n",
    "fig=gmaps.figure()\n",
    "\n",
    "heatmap_layer = gmaps.heatmap_layer(locations)\n",
    "heatmap_layer.max_intensity = 100\n",
    "heatmap_layer.point_radius = 5\n",
    "fig.add_layer(gmaps.transit_layer())\n",
    "fig.add_layer(gmaps.heatmap_layer(locations, weights=weights))\n",
    "\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = merge_table[['LAT','LNG']]\n",
    "\n",
    "weights = merge_table['transitscore']\n",
    "\n",
    "fig_transit=gmaps.figure()\n",
    "heatmap_layer = gmaps.heatmap_layer(locations)\n",
    "fig_transit.add_layer(gmaps.transit_layer())\n",
    "heatmap_layer.max_intensity = 100\n",
    "heatmap_layer.point_radius = 5\n",
    "fig_transit.add_layer(gmaps.heatmap_layer(locations, weights=weights))\n",
    "\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "locations = merge_table[['LAT','LNG']]\n",
    "\n",
    "weights = merge_table['bikescore']\n",
    "\n",
    "fig_bike=gmaps.figure()\n",
    "heatmap_layer = gmaps.heatmap_layer(locations)\n",
    "fig_bike.add_layer(gmaps.bicycling_layer())\n",
    "heatmap_layer.max_intensity = 100\n",
    "heatmap_layer.point_radius = 5\n",
    "fig_bike.add_layer(gmaps.heatmap_layer(locations, weights=weights))\n",
    "\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpts = list(np.linspace(1,12, len(colors) -1))\n",
    "\n",
    "fips = merge_table['ZipCode'].tolist()\n",
    "values = merge_table['Population_x'].tolist()\n",
    "\n",
    "fig = ff.create_choropleth(fips=fips, values=values, scope=['usa'],\n",
    "                          binning_endpoints = endpts, colorscale = colors,\n",
    "                          show_state_data=False, show_hover = True,\n",
    "                          centroid_marker={'opacity':0},\n",
    "                          asp=2.9, title=\"Population by ZipCode\",\n",
    "                          legend_title=\"Population\"\n",
    "                          )\n",
    "\n",
    "py.iplot(fig, filename=\"choropleth_chicago\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
